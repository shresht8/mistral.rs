{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T10:41:43.487582200Z",
     "start_time": "2024-05-16T10:41:43.458227600Z"
    }
   },
   "outputs": [],
   "source": [
    "from mistralrs import Runner, Which, ChatCompletionRequest, Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "PanicException",
     "evalue": "called `Result::unwrap()` on an `Err` value: LoadLibraryExW { source: Os { code: 126, kind: Uncategorized, message: \"The specified module could not be found.\" } }",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPanicException\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m runner \u001B[38;5;241m=\u001B[39m \u001B[43mRunner\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwhich\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mWhich\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGGUF\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtok_model_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmeta-llama/Meta-Llama-3-8B-Instruct\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquantized_model_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbartowski/Meta-Llama-3-8B-Instruct-GGUF\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquantized_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMeta-Llama-3-8B-Instruct-Q6_K.gguf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_json\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepeat_last_n\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[1;31mPanicException\u001B[0m: called `Result::unwrap()` on an `Err` value: LoadLibraryExW { source: Os { code: 126, kind: Uncategorized, message: \"The specified module could not be found.\" } }"
     ]
    }
   ],
   "source": [
    "\n",
    "# runner = Runner(\n",
    "#     which=Which.GGUF(\n",
    "#         tok_model_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#         quantized_model_id=\"bartowski/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "#         quantized_filename=\"Meta-Llama-3-8B-Instruct-Q6_K.gguf\",\n",
    "#         tokenizer_json=None,\n",
    "#         repeat_last_n=64,\n",
    "#     )\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T11:34:54.380457600Z",
     "start_time": "2024-05-15T11:34:54.020083300Z"
    }
   },
   "id": "5c1bcdcdd3cf6ba3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "PanicException",
     "evalue": "called `Result::unwrap()` on an `Err` value: LoadLibraryExW { source: Os { code: 126, kind: Uncategorized, message: \"The specified module could not be found.\" } }",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPanicException\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m runner \u001B[38;5;241m=\u001B[39m \u001B[43mRunner\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwhich\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mWhich\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGGUF\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtok_model_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquantized_model_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTheBloke/Mistral-7B-Instruct-v0.1-GGUF\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquantized_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmistral-7b-instruct-v0.1.Q4_K_M.gguf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_json\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepeat_last_n\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[1;31mPanicException\u001B[0m: called `Result::unwrap()` on an `Err` value: LoadLibraryExW { source: Os { code: 126, kind: Uncategorized, message: \"The specified module could not be found.\" } }"
     ]
    }
   ],
   "source": [
    "runner = Runner(\n",
    "    which=Which.GGUF(\n",
    "        tok_model_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        quantized_model_id=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "        quantized_filename=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "        tokenizer_json=None,\n",
    "        repeat_last_n=64,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T21:06:00.223786500Z",
     "start_time": "2024-05-15T21:05:59.524937500Z"
    }
   },
   "id": "5e3f81f49a735f8d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "PanicException",
     "evalue": "called `Result::unwrap()` on an `Err` value: PoisonError { .. }",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPanicException\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m runner \u001B[38;5;241m=\u001B[39m \u001B[43mRunner\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwhich\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mWhich\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPlain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43march\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mArchitecture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMistral\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_json\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepeat_last_n\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[1;31mPanicException\u001B[0m: called `Result::unwrap()` on an `Err` value: PoisonError { .. }"
     ]
    }
   ],
   "source": [
    "runner = Runner(\n",
    "    which=Which.Plain(\n",
    "        model_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "        arch=Architecture.Mistral,\n",
    "        tokenizer_json=None,\n",
    "        repeat_last_n=64,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T11:39:20.747995Z",
     "start_time": "2024-05-15T11:39:20.693998400Z"
    }
   },
   "id": "e6eebddc1a46e5c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = runner.send_chat_completion_request(\n",
    "    ChatCompletionRequest(\n",
    "        model=\"llama\",\n",
    "        messages=[{\"role\":\"user\", \"content\":\"Tell me a story about the Rust type system.\"}],\n",
    "        max_tokens=256,\n",
    "        presence_penalty=1.0,\n",
    "        top_p=0.1,\n",
    "        temperature=0.1,\n",
    "    )\n",
    ")\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "489c670aee9378d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "hf-pytorch",
   "language": "python",
   "display_name": "hf-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
